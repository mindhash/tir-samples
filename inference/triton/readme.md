# Triton Inference Server on TIR


### Getting Started 

### Architecture 

### Adding requirements.txt 

### Multi-GPU Setup 

### Backends:

#### Python Backend

#### Tensor-RT LLM 


### Examples
